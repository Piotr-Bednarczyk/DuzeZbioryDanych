{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec15e2d9-3e9e-47d8-bd48-33bf8b4512b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting findspark\n",
      "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: findspark\n",
      "Successfully installed findspark-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7febced7-7224-44ad-9e61-48237824bd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/01/11 00:19:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-----------+------------------+--------------------+--------------+----------+---------------+----------+-----------+---------+-----------+-----+----------+--------------------+\n",
      "|_c0|recipe_number|recipe_code|       recipe_name|          comment_id|       user_id| user_name|user_reputation|created_at|reply_count|thumbs_up|thumbs_down|stars|best_score|                text|\n",
      "+---+-------------+-----------+------------------+--------------------+--------------+----------+---------------+----------+-----------+---------+-----------+-----+----------+--------------------+\n",
      "|  0|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_9iFLIhMa8QaG|   Jeri326|              1|1665619889|          0|        0|          0|    5|       527|I tweaked it a li...|\n",
      "|  1|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_Lu6p25tmE77j|   Mark467|             50|1665277687|          0|        7|          0|    5|       724|Bush used to have...|\n",
      "|  2|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_s0LwgpZ8Jsqq|Barbara566|             10|1664404557|          0|        3|          0|    5|       710|I have a very com...|\n",
      "|  3|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_fqrybAdYjgjG|jeansch123|              1|1661787808|          2|        2|          0|    0|       581|In your introduct...|\n",
      "|  4|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_XXWKwVhKZD69|  camper77|             10|1664913823|          1|        7|          0|    0|       820|Wonderful! I made...|\n",
      "+---+-------------+-----------+------------------+--------------------+--------------+----------+---------------+----------+-----------+---------+-----------+-----+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- recipe_number: string (nullable = true)\n",
      " |-- recipe_code: string (nullable = true)\n",
      " |-- recipe_name: string (nullable = true)\n",
      " |-- comment_id: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- user_name: string (nullable = true)\n",
      " |-- user_reputation: string (nullable = true)\n",
      " |-- created_at: integer (nullable = true)\n",
      " |-- reply_count: integer (nullable = true)\n",
      " |-- thumbs_up: integer (nullable = true)\n",
      " |-- thumbs_down: integer (nullable = true)\n",
      " |-- stars: integer (nullable = true)\n",
      " |-- best_score: integer (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/11 00:19:12 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , recipe_number, recipe_code, recipe_name, comment_id, user_id, user_name, user_reputation, created_at, reply_count, thumbs_up, thumbs_down, stars, best_score, text\n",
      " Schema: _c0, recipe_number, recipe_code, recipe_name, comment_id, user_id, user_name, user_reputation, created_at, reply_count, thumbs_up, thumbs_down, stars, best_score, text\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///opt/spark/work-dir/data/Recipe%20Reviews%20and%20User%20Feedback%20Dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "import zipfile\n",
    "import random\n",
    "from decimal import Decimal\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DecimalType\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .appName(\"Create-DataFrame\") \\\n",
    "    .config(\"spark.executorEnv.PYSPARK_PYTHON\", \"python3\") \\\n",
    "    .config(\"spark.executorEnv.PYSPARK_DRIVER_PYTHON\", \"python3\") \\\n",
    "    .config(\"spark.memory.offHeap.enabled\", \"true\") \\\n",
    "    .config(\"spark.memory.offHeap.size\", \"6g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/911/recipe+reviews+and+user+feedback+dataset.zip\"\n",
    "response = requests.get(url)\n",
    "with open(\"recipe_reviews.zip\", \"wb\") as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "data_folder = \"./data\"\n",
    "with zipfile.ZipFile(\"recipe_reviews.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(data_folder)\n",
    "\n",
    "df_reviews = spark.read.csv(f'{data_folder}/Recipe Reviews and User Feedback Dataset.csv', header=True, sep=',', inferSchema=True)\n",
    "df_reviews.show(5)\n",
    "df_reviews.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8747e3c5-86d8-4f7d-8392-dd5584570c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|reply_count|\n",
      "+-----------+\n",
      "|          3|\n",
      "|          3|\n",
      "|          3|\n",
      "|          3|\n",
      "|          3|\n",
      "|          3|\n",
      "|          2|\n",
      "|          2|\n",
      "|          2|\n",
      "|          2|\n",
      "+-----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----------+---------------+\n",
      "|recipe_code|sum(best_score)|\n",
      "+-----------+---------------+\n",
      "|       2832|          98863|\n",
      "|      14299|          85497|\n",
      "|      17826|          64880|\n",
      "|       3309|          64247|\n",
      "|      21444|          60755|\n",
      "|      32480|          59867|\n",
      "|      12540|          59195|\n",
      "|       2912|          54032|\n",
      "|      42083|          51975|\n",
      "|      19731|          47905|\n",
      "+-----------+---------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----------+-----+\n",
      "|recipe_code|count|\n",
      "+-----------+-----+\n",
      "|       2832|  725|\n",
      "|      14299|  654|\n",
      "|       3309|  509|\n",
      "|      42083|  421|\n",
      "|      32480|  397|\n",
      "|      21444|  395|\n",
      "|      12540|  368|\n",
      "|      17826|  338|\n",
      "|       2912|  332|\n",
      "|      19731|  324|\n",
      "+-----------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----+-----+\n",
      "|stars|count|\n",
      "+-----+-----+\n",
      "| NULL|   86|\n",
      "|    0| 1696|\n",
      "|    1|  280|\n",
      "|    2|  232|\n",
      "|    3|  490|\n",
      "|    4| 1655|\n",
      "|    5|13829|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Zadanie 1\n",
    "df_reviews = df_reviews.withColumnRenamed(\"_c0\", \"id\")\n",
    "\n",
    "df_reviews.select(\"reply_count\").orderBy(\"reply_count\", ascending=False).show(10)\n",
    "\n",
    "df_reviews.groupBy(\"recipe_code\").sum(\"best_score\").orderBy(\"sum(best_score)\", ascending=False).show(10)\n",
    "\n",
    "df_reviews.groupBy(\"recipe_code\").count().orderBy(\"count\", ascending=False).show(10)\n",
    "\n",
    "df_reviews.groupBy(\"stars\").count().orderBy(\"stars\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba7b0e23-0401-45da-9b81-e1faaab01819",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-------------------+---+--------+\n",
      "| id| firstname|           lastname|age|  salary|\n",
      "+---+----------+-------------------+---+--------+\n",
      "|  1|  Zbigniew|         Wróblewski| 48|11138.91|\n",
      "|  2|Aleksandra|             Szczaw| 52| 7716.22|\n",
      "|  3|  Zbigniew|         Wróblewski| 40|11314.07|\n",
      "|  4|Aleksandra|              Pysla| 37| 9796.99|\n",
      "|  5|      Adam|             Wlotka| 38| 9545.44|\n",
      "|  6|Aleksandra|Brzęczyszczykiewicz| 67| 8579.71|\n",
      "|  7|Mieczysław|           Kowalski| 38| 5369.43|\n",
      "|  8|     Marek|       Mieczykowski| 46| 9552.36|\n",
      "|  9|      Adam|         Wróblewski| 43| 5876.42|\n",
      "| 10|  Wojciech|         Malinowski| 19|10499.58|\n",
      "+---+----------+-------------------+---+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "data_schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), False),\n",
    "    StructField(\"firstname\", StringType(), True),\n",
    "    StructField(\"lastname\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"salary\", DecimalType(10, 2), True)\n",
    "])\n",
    "\n",
    "firstnames = [\"Adam\", \"Katarzyna\", \"Krzysztof\", \"Marek\", \"Aleksandra\", \"Zbigniew\", \"Wojciech\", \"Mieczysław\", \"Agata\", \"Wisława\"]\n",
    "lastnames = [\"Mieczykowski\", \"Kowalski\", \"Malinowski\", \"Szczaw\", \"Glut\", \"Barański\", \"Brzęczyszczykiewicz\", \"Wróblewski\", \"Wlotka\", \"Pysla\"]\n",
    "age_range = (18, 68)\n",
    "salary_range = (3200, 12500)\n",
    "\n",
    "data = [\n",
    "    (i, random.choice(firstnames), random.choice(lastnames), random.randint(*age_range), Decimal(round(random.uniform(*salary_range), 2)))\n",
    "    for i in range(1, 1001)\n",
    "]\n",
    "\n",
    "df_employee = spark.createDataFrame(data, schema=data_schema)\n",
    "df_employee.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1cb3190-afbf-4455-8885-8fcacd9e81e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /home/spark/.local/lib/python3.10/site-packages (2.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "604dfeb8-f7e9-4fde-b848-4e16765c10b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czas wykonania: 0.27700138092041016 sekund\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "df_employee.filter(df_employee[\"salary\"] > 10000).count()\n",
    "print(f\"Czas wykonania: {time.time() - start_time} sekund\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4aae1bd9-d108-4630-b77d-7d13c80cfee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+\n",
      "|age|age_bucket|\n",
      "+---+----------+\n",
      "| 48|       3.0|\n",
      "| 52|       4.0|\n",
      "| 40|       3.0|\n",
      "| 37|       2.0|\n",
      "| 38|       2.0|\n",
      "| 67|       5.0|\n",
      "| 38|       2.0|\n",
      "| 46|       3.0|\n",
      "| 43|       3.0|\n",
      "| 19|       0.0|\n",
      "| 48|       3.0|\n",
      "| 26|       1.0|\n",
      "| 32|       2.0|\n",
      "| 34|       2.0|\n",
      "| 31|       2.0|\n",
      "| 62|       5.0|\n",
      "| 31|       2.0|\n",
      "| 20|       1.0|\n",
      "| 33|       2.0|\n",
      "| 29|       1.0|\n",
      "+---+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+-----+\n",
      "|age_bucket|count|\n",
      "+----------+-----+\n",
      "|       0.0|   39|\n",
      "|       1.0|  177|\n",
      "|       2.0|  197|\n",
      "|       3.0|  211|\n",
      "|       4.0|  208|\n",
      "|       5.0|  168|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def bucketize_age(df, input_col, output_col):\n",
    "    from pyspark.ml.feature import Bucketizer\n",
    "    splits = [10, 20, 30, 40, 50, 60, 70]\n",
    "    bucketizer = Bucketizer(splits=splits, inputCol=input_col, outputCol=output_col)\n",
    "    return bucketizer.transform(df)\n",
    "\n",
    "df_employee = bucketize_age(df_employee, \"age\", \"age_bucket\")\n",
    "df_employee.select(\"age\", \"age_bucket\").show(20)\n",
    "\n",
    "age_distribution = df_employee.groupBy(\"age_bucket\").count().orderBy(\"age_bucket\")\n",
    "age_distribution.show()\n",
    "\n",
    "sc.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d35450c-9fe0-4148-9fee-e6b52c95e371",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
